{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "out_path='outputs/AbdomenCTCT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Learn2Reg_Dataset_release_v1.0/AbdomenCTCT/AbdomenCTCT_dataset.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m##preload data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m data_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../Learn2Reg_Dataset_release_v1.0/AbdomenCTCT/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_path,\u001b[39m'\u001b[39;49m\u001b[39mAbdomenCTCT_dataset.json\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m     dataset_info\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m val_list\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m([x[\u001b[39m'\u001b[39m\u001b[39mfixed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dataset_info[\u001b[39m'\u001b[39m\u001b[39mregistration_val\u001b[39m\u001b[39m'\u001b[39m]] \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m               \u001b[39m+\u001b[39m [x[\u001b[39m'\u001b[39m\u001b[39mmoving\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dataset_info[\u001b[39m'\u001b[39m\u001b[39mregistration_val\u001b[39m\u001b[39m'\u001b[39m]])))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Learn2Reg_Dataset_release_v1.0/AbdomenCTCT/AbdomenCTCT_dataset.json'"
     ]
    }
   ],
   "source": [
    "##preload data\n",
    "\n",
    "data_path='../Learn2Reg_Dataset_release_v1.0/AbdomenCTCT/'\n",
    "with open(os.path.join(data_path,'AbdomenCTCT_dataset.json')) as f:\n",
    "    dataset_info=json.load(f)\n",
    "\n",
    "val_list=sorted(list(set([x['fixed'] for x in dataset_info['registration_val']] \n",
    "              + [x['moving'] for x in dataset_info['registration_val']])))\n",
    "validation_ = dataset_info['registration_val']\n",
    "training_ = [x for x in dataset_info['training'] if x['image'] not in val_list]\n",
    "H,W,D = dataset_info['tensorImageShape']['0']\n",
    "num_val=len(val_list); num_train=len(training_)\n",
    "print('Training:',len(training_),'; Validation',len(val_list))\n",
    "\n",
    "\n",
    "##validation\n",
    "seg_val = torch.zeros(num_val,H,W,D).long().pin_memory()\n",
    "img_val = torch.zeros(num_val,1,H//2,W//2,D//2).pin_memory()\n",
    "t0 = time.time()\n",
    "for ii,i in enumerate(val_list):\n",
    "    seg_val[ii] = torch.from_numpy(nib.load(os.path.join(data_path,i.replace('image','label'))).get_fdata()).long()\n",
    "    img_val[ii] = F.avg_pool3d(torch.from_numpy(nib.load(os.path.join(data_path,i)).get_fdata()).float().cuda().unsqueeze(0).unsqueeze(0)/500,2).cpu()\n",
    "t1 = time.time()\n",
    "print('validaion data loaded in %.2f s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000003vscode-remote?line=97'>98</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal(x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000003vscode-remote?line=99'>100</a>\u001b[0m resnet \u001b[39m=\u001b[39m UNet2()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000003vscode-remote?line=101'>102</a>\u001b[0m resnet\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000003vscode-remote?line=102'>103</a>\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=670'>671</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=671'>672</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=672'>673</a>\u001b[0m \n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=673'>674</a>\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=685'>686</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=686'>687</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=687'>688</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 578 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=596'>597</a>\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=597'>598</a>\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=598'>599</a>\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=599'>600</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=600'>601</a>\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=601'>602</a>\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=602'>603</a>\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=670'>671</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=671'>672</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=672'>673</a>\u001b[0m \n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=673'>674</a>\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=685'>686</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=686'>687</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/modules/module.py?line=687'>688</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### functions \n",
    "def jacobian_determinant_3d(dense_flow):\n",
    "    B,_,H,W,D = dense_flow.size()\n",
    "    \n",
    "    dense_pix = dense_flow*(torch.Tensor([H-1,W-1,D-1])/2).view(1,3,1,1,1).to(dense_flow.device)\n",
    "    gradz = nn.Conv3d(3,3,(3,1,1),padding=(1,0,0),bias=False,groups=3)\n",
    "    gradz.weight.data[:,0,:,0,0] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    gradz.to(dense_flow.device)\n",
    "    grady = nn.Conv3d(3,3,(1,3,1),padding=(0,1,0),bias=False,groups=3)\n",
    "    grady.weight.data[:,0,0,:,0] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    grady.to(dense_flow.device)\n",
    "    gradx = nn.Conv3d(3,3,(1,1,3),padding=(0,0,1),bias=False,groups=3)\n",
    "    gradx.weight.data[:,0,0,0,:] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    gradx.to(dense_flow.device)\n",
    "    #with torch.no_grad():\n",
    "    jacobian = torch.cat((gradz(dense_pix),grady(dense_pix),gradx(dense_pix)),0)+torch.eye(3,3).view(3,3,1,1,1).to(dense_flow.device)\n",
    "    jacobian = jacobian[:,:,2:-2,2:-2,2:-2]\n",
    "    jac_det = jacobian[0,0,:,:,:]*(jacobian[1,1,:,:,:]*jacobian[2,2,:,:,:]-jacobian[1,2,:,:,:]*jacobian[2,1,:,:,:])-\\\n",
    "    jacobian[1,0,:,:,:]*(jacobian[0,1,:,:,:]*jacobian[2,2,:,:,:]-jacobian[0,2,:,:,:]*jacobian[2,1,:,:,:])+\\\n",
    "    jacobian[2,0,:,:,:]*(jacobian[0,1,:,:,:]*jacobian[1,2,:,:,:]-jacobian[0,2,:,:,:]*jacobian[1,1,:,:,:])\n",
    "\n",
    "    return jac_det\n",
    "\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = torch.mean(iflat * tflat)\n",
    "        dice[label_num-1] = (2. * intersection) / (1e-8 + torch.mean(iflat) + torch.mean(tflat))\n",
    "    return dice\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(in_channels,out_channels,3,padding=1,bias=False),\\\n",
    "                                   nn.BatchNorm3d(out_channels),nn.PReLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(out_channels,out_channels,1,bias=False),\\\n",
    "                                   nn.BatchNorm3d(out_channels),nn.PReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)\n",
    "    \n",
    "base_ch = 16\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleDict({'enc1':ConvBlock(64,base_ch*2),'enc2':ConvBlock(base_ch*2,base_ch*3),\\\n",
    "                                      'enc3':ConvBlock(base_ch*3,base_ch*3),'enc4':ConvBlock(base_ch*3,base_ch*4)})\n",
    "        self.decoder = nn.ModuleDict({'dec1':ConvBlock(base_ch*7,base_ch*3),\\\n",
    "                                      'dec2':ConvBlock(base_ch*6,base_ch*3),'dec3':ConvBlock(base_ch*5,base_ch*2)})\n",
    "        self.conv1 = ConvBlock(base_ch*2,base_ch*4)\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(base_ch*4,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,3,1))\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        upsample = nn.Upsample(scale_factor=2,mode='trilinear')\n",
    "        for i in range(4):\n",
    "            x = self.encoder['enc'+str(i+1)](x)\n",
    "            if(i<3):\n",
    "                y.append(x)\n",
    "                x = F.max_pool3d(x,2) \n",
    "        for i in range(3):\n",
    "            x = torch.cat((upsample(x),y.pop()),1)\n",
    "            x = self.decoder['dec'+str(i+1)](x)\n",
    "        x = self.conv1(x)\n",
    "        return F.avg_pool3d(F.avg_pool3d(upsample(self.conv2(x)),5,stride=1,padding=2),5,stride=1,padding=2)\n",
    "    \n",
    "class UNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleDict({'enc1':ConvBlock(1,base_ch*2),'enc2':ConvBlock(base_ch*2,base_ch*3),\\\n",
    "                                      'enc3':ConvBlock(base_ch*3,base_ch*3),'enc4':ConvBlock(base_ch*3,base_ch*4),\\\n",
    "                                      'enc5':ConvBlock(base_ch*4,base_ch*4)})\n",
    "        self.decoder = nn.ModuleDict({'dec1':ConvBlock(base_ch*8,base_ch*3),'dec2':ConvBlock(base_ch*6,base_ch*3),\\\n",
    "                                      'dec3':ConvBlock(base_ch*6,base_ch*3),'dec4':ConvBlock(base_ch*3,base_ch*2)})\n",
    "        self.conv1 = ConvBlock(base_ch*2,base_ch*4)\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(base_ch*4,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,32,1))\n",
    "        self.final = nn.Identity()\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        upsample = nn.Upsample(scale_factor=2,mode='trilinear')\n",
    "        for i in range(5):\n",
    "            x = self.encoder['enc'+str(i+1)](x)\n",
    "            if(i<4):\n",
    "                y.append(x)\n",
    "                x = F.max_pool3d(x,2) \n",
    "        for i in range(4):\n",
    "            if(i<3):\n",
    "                x = torch.cat((upsample(x),y.pop()),1)\n",
    "            x = self.decoder['dec'+str(i+1)](x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.final(x)\n",
    "\n",
    "resnet = UNet2()\n",
    "\n",
    "resnet.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m models \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mAbdomenCTCT_example_complete.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m unet\u001b[39m=\u001b[39mUNet()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m unet\u001b[39m.\u001b[39mload_state_dict(models[\u001b[39m'\u001b[39m\u001b[39munet\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m resnet\u001b[39m.\u001b[39mload_state_dict(models[\u001b[39m'\u001b[39m\u001b[39mresnet\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UNet' is not defined"
     ]
    }
   ],
   "source": [
    "models = torch.load('AbdomenCTCT_example_complete.pth')\n",
    "unet=UNet()\n",
    "unet.load_state_dict(models['unet'])\n",
    "resnet.load_state_dict(models['resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m unet\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000006vscode-remote?line=1'>2</a>\u001b[0m resnet\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht02/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/Workspace/Example_AbdomenCTCT_inference.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m unet\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unet' is not defined"
     ]
    }
   ],
   "source": [
    "unet.cuda()\n",
    "resnet.cuda()\n",
    "unet.eval()\n",
    "resnet.eval()\n",
    "dice45 = torch.zeros(4,45)\n",
    "t_all = 0\n",
    "count = 0\n",
    "\n",
    "val_list_nr=[int(x[-16:-12]) for x in val_list]\n",
    "\n",
    "for i,val1 in enumerate(val_list_nr):\n",
    "    for j, val2 in enumerate(val_list_nr):\n",
    "        if(i>=j):\n",
    "            continue\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                feat = resnet(torch.cat((img_val[i:i+1].cuda(),img_val[j:j+1].cuda()),0))\n",
    "                input = torch.cat((feat[:1],feat[1:2]),1).cuda()\n",
    "\n",
    "                output = F.interpolate(unet(input),scale_factor=2,mode='trilinear')\n",
    "\n",
    "\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.time()   \n",
    "        t_all += (t1-t0)\n",
    "        with torch.no_grad():\n",
    "            seg_warped = F.grid_sample(seg_val[j:j+1].unsqueeze(1).float().contiguous().cuda(),output.permute(0,2,3,4,1)+F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H,W,D)),mode='nearest')\n",
    "            jac_det = jacobian_determinant_3d(output[:1])\n",
    "        d0 = dice_coeff(seg_val[i].cuda().contiguous(),seg_val[j].contiguous().cuda().long(),14).cpu()\n",
    "\n",
    "        nib_disp_field=((output.permute(0,2,3,4,1) /2)*(torch.tensor([D,W,H]).cuda()-1)).flip(-1).float().squeeze().cpu()\n",
    "        nib.save(nib.Nifti1Image(nib_disp_field.numpy(), np.eye(4)), os.path.join(out_path, f'disp_{str(val1).zfill(4)}_{str(val2).zfill(4)}.nii.gz'))\n",
    "        print(f'Saved disp_{str(val1).zfill(4)}_{str(val2).zfill(4)}.nii.gz')\n",
    "\n",
    "        d1 = dice_coeff(seg_val[i].cuda().contiguous(),seg_warped.contiguous().squeeze().long(),14).cpu()\n",
    "        #print(d1.mean(),d1)\n",
    "        dice45[0,count] = d0.mean()\n",
    "        dice45[1,count] = d1.mean()\n",
    "        dice45[2,count] = jac_det.std()\n",
    "        dice45[3,count] = (jac_det<0).float().mean()\n",
    "\n",
    "\n",
    "\n",
    "        count += 1\n",
    "    #print(d0.mean(),'after',d1.mean(),jac_det.std(),(jac_det<0).float().mean())\n",
    "\n",
    "print('%0.4f'%((t_all)/45),'sec/im','Dice before (%)','%0.2f'%(dice45.mean(1)[0].item()*100),\\\n",
    "      'Dice after (%)','%0.2f'%(dice45.mean(1)[1].item()*100),'std(Jac)','%0.4f'%(dice45.mean(1)[2].item()),\\\n",
    "     'neg(Jac)','%0.6f'%(dice45.mean(1)[3].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring AbdomenCTCT\n",
      "/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "Evaluate 45 cases for: ['LogJacDetStd', 'DSC', 'HD95']\n",
      "case_results [0]: {'LogJacDetStd': 0.20462614505862706, 'DSC': 0.39922989052677466, 'HD95': 15.941665132646175}\n",
      "case_results [1]: {'LogJacDetStd': 0.5610970450765086, 'DSC': 0.406835919616467, 'HD95': 13.465253039064285}\n",
      "case_results [2]: {'LogJacDetStd': 0.32042365233439846, 'DSC': 0.48873730132386256, 'HD95': 10.251239470858536}\n",
      "case_results [3]: {'LogJacDetStd': 0.15681494660454515, 'DSC': 0.4706736001567782, 'HD95': 11.234598568885923}\n",
      "case_results [4]: {'LogJacDetStd': 0.5534540337250122, 'DSC': 0.5057861434252648, 'HD95': 13.167800513595797}\n",
      "case_results [5]: {'LogJacDetStd': 0.32016340046257413, 'DSC': 0.4660128655617776, 'HD95': 12.41152448525145}\n",
      "case_results [6]: {'LogJacDetStd': 0.15541076496174838, 'DSC': 0.503868161779433, 'HD95': 10.614256204659345}\n",
      "case_results [7]: {'LogJacDetStd': 0.15703455437882086, 'DSC': 0.5577241877727651, 'HD95': 7.6303550909217455}\n",
      "case_results [8]: {'LogJacDetStd': 0.16929413910828164, 'DSC': 0.5152876889981639, 'HD95': 7.305151844839115}\n",
      "case_results [9]: {'LogJacDetStd': 0.3794716565934051, 'DSC': 0.380557870358443, 'HD95': 15.632925346893035}\n",
      "case_results [10]: {'LogJacDetStd': 0.8857704653857261, 'DSC': 0.4029300788418303, 'HD95': 14.604800599074727}\n",
      "case_results [11]: {'LogJacDetStd': 0.6750902402070454, 'DSC': 0.3769887262184604, 'HD95': 15.218956051901147}\n",
      "case_results [12]: {'LogJacDetStd': 1.1434748916376642, 'DSC': 0.3932533313610517, 'HD95': 14.566102017622354}\n",
      "case_results [13]: {'LogJacDetStd': 0.9664650877747675, 'DSC': 0.3591237100019573, 'HD95': 14.618510980609512}\n",
      "case_results [14]: {'LogJacDetStd': 0.33363504479957945, 'DSC': 0.41349244962268944, 'HD95': 12.178509448468779}\n",
      "case_results [15]: {'LogJacDetStd': 0.7137664872928025, 'DSC': 0.4592763823070445, 'HD95': 12.300731212159887}\n",
      "case_results [16]: {'LogJacDetStd': 0.4117102991425134, 'DSC': 0.40444678169787174, 'HD95': 14.01349959125638}\n",
      "case_results [17]: {'LogJacDetStd': 0.38761083188675205, 'DSC': 0.4282962728903415, 'HD95': 13.525773816468558}\n",
      "case_results [18]: {'LogJacDetStd': 0.16419488748776542, 'DSC': 0.3891235454807826, 'HD95': 14.72540428478691}\n",
      "case_results [19]: {'LogJacDetStd': 0.3088598003236433, 'DSC': 0.4476926747911294, 'HD95': 13.056903658798936}\n",
      "case_results [20]: {'LogJacDetStd': 0.2412384923084534, 'DSC': 0.42755205906802873, 'HD95': 15.118900405773537}\n",
      "case_results [21]: {'LogJacDetStd': 0.24848071666932192, 'DSC': 0.410465256208806, 'HD95': 17.29549594286752}\n",
      "case_results [22]: {'LogJacDetStd': 0.4026404049559161, 'DSC': 0.45936078762503635, 'HD95': 14.581504389507677}\n",
      "case_results [23]: {'LogJacDetStd': 0.3556092242851712, 'DSC': 0.4273303112605903, 'HD95': 15.499131101012933}\n",
      "case_results [24]: {'LogJacDetStd': 0.162838606800224, 'DSC': 0.44618426796590116, 'HD95': 11.969444155482902}\n",
      "case_results [25]: {'LogJacDetStd': 0.452056025234921, 'DSC': 0.5539291825768576, 'HD95': 10.475600446820625}\n",
      "case_results [26]: {'LogJacDetStd': 0.4559057417578507, 'DSC': 0.46111480757388007, 'HD95': 16.02230318695879}\n",
      "case_results [27]: {'LogJacDetStd': 0.26101425080226587, 'DSC': 0.5320710916378342, 'HD95': 12.649997541899241}\n",
      "case_results [28]: {'LogJacDetStd': 0.17112018684322192, 'DSC': 0.5223907533201414, 'HD95': 13.737615022505976}\n",
      "case_results [29]: {'LogJacDetStd': 0.17019872310585477, 'DSC': 0.524607286280533, 'HD95': 10.288343361649748}\n",
      "case_results [30]: {'LogJacDetStd': 0.7680101946249036, 'DSC': 0.4356980268349285, 'HD95': 10.771066167886156}\n",
      "case_results [31]: {'LogJacDetStd': 0.579303459352603, 'DSC': 0.4228663730096958, 'HD95': 11.703034162648075}\n",
      "case_results [32]: {'LogJacDetStd': 0.5770178834761415, 'DSC': 0.4491508243715408, 'HD95': 11.706939486619644}\n",
      "case_results [33]: {'LogJacDetStd': 0.39203588497698333, 'DSC': 0.45858151013535137, 'HD95': 14.079469212392192}\n",
      "case_results [34]: {'LogJacDetStd': 0.48659029894234684, 'DSC': 0.463511033950635, 'HD95': 10.625079704276072}\n",
      "case_results [35]: {'LogJacDetStd': 0.20359272096847184, 'DSC': 0.48104675104344913, 'HD95': 13.647307467818136}\n",
      "case_results [36]: {'LogJacDetStd': 0.1637764974036163, 'DSC': 0.4934537843217165, 'HD95': 13.97465306980163}\n",
      "case_results [37]: {'LogJacDetStd': 0.1919602710958925, 'DSC': 0.5013852469571792, 'HD95': 14.961789261237378}\n",
      "case_results [38]: {'LogJacDetStd': 0.1820238556811124, 'DSC': 0.4978161267853558, 'HD95': 13.653066639011232}\n",
      "case_results [39]: {'LogJacDetStd': 0.18848831989871487, 'DSC': 0.4756509246579203, 'HD95': 11.600415181613345}\n",
      "case_results [40]: {'LogJacDetStd': 0.21910528623853265, 'DSC': 0.5024201098339596, 'HD95': 14.896522819178374}\n",
      "case_results [41]: {'LogJacDetStd': 0.2872535028967512, 'DSC': 0.4734998285862172, 'HD95': 11.504283309999094}\n",
      "case_results [42]: {'LogJacDetStd': 0.15923332490851325, 'DSC': 0.5733929898478347, 'HD95': 7.258462785810028}\n",
      "case_results [43]: {'LogJacDetStd': 0.45591447917774797, 'DSC': 0.5160876843331699, 'HD95': 7.123388972290339}\n",
      "case_results [44]: {'LogJacDetStd': 0.23771793571655137, 'DSC': 0.5354157075926499, 'HD95': 8.026888722835366}\n",
      "{\n",
      "    \"LogJacDetStd\": {\n",
      "        \"30\": 0.20379940578650288,\n",
      "        \"std\": 0.2368012258616644,\n",
      "        \"mean\": 0.3773665480525393\n",
      "    },\n",
      "    \"DSC\": {\n",
      "        \"30\": 0.42770090183249126,\n",
      "        \"std\": 0.053070851784151656,\n",
      "        \"mean\": 0.46254045130026894\n",
      "    },\n",
      "    \"HD95\": {\n",
      "        \"30\": 11.620938977820291,\n",
      "        \"std\": 2.539015618722733,\n",
      "        \"mean\": 12.658548086147968\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "displacement_fields= '/share/data_zoe3/grossbroehmer/Learn2Reg2022/baselines/outputs/AbdomenCTCT/'\n",
    "data='/share/data_zoe3/grossbroehmer/Learn2Reg2022/Learn2Reg_Dataset_v1/'\n",
    "config_files_dir='/share/data_zoe3/grossbroehmer/Learn2Reg2022/L2R/evaluation/evaluation_configs'\n",
    "output_dir=displacement_fields#'/share/data_zoe3/grossbroehmer/Learn2Reg2022/evaluation/results'\n",
    "output_suffix='_example.json'\n",
    "for task in ['AbdomenCTCT']:\n",
    "    print('Staring', task)\n",
    "    _i=os.path.join(displacement_fields)\n",
    "    _d=os.path.join(data,task)\n",
    "    _o=os.path.join(output_dir,task+output_suffix)\n",
    "    _c=os.path.join(config_files_dir,task+\"_VAL_evaluation_config.json\")\n",
    "    !python /share/data_zoe3/grossbroehmer/Learn2Reg2022/L2R/evaluation/evaluation.py -i {_i} -d {_d} -o{_o} -c{_c} -v\n",
    "    print(2*'\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ea9f0d30abf61677a25ad12401e4e23082d5add844bfb861bed0be870feaf59"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
