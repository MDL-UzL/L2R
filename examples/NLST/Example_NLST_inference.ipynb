{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "data_path='../../Learn2Reg_Dataset_release_v1.1/NLST/'\n",
    "with open(os.path.join(data_path,'NLST_dataset.json')) as f:\n",
    "    dataset_json = json.load(f)\n",
    "list_val=dataset_json['registration_val']\n",
    "ori_shape=dataset_json['tensorImageShape']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "##load validation data\n",
    "\n",
    "H=ori_shape[0]//2\n",
    "W=ori_shape[1]//2\n",
    "D=ori_shape[2]//2\n",
    "\n",
    "img_fix=torch.zeros((len(list_val),1,H,W,D)).float()\n",
    "img_mov=torch.zeros((len(list_val),1,H,W,D)).float()\n",
    "mask_fix=torch.zeros((len(list_val),1,H,W,D)).int()\n",
    "mask_mov=torch.zeros((len(list_val),1,H,W,D)).int()\n",
    "\n",
    "\n",
    "for idx,value in enumerate(list_val):\n",
    "    img_fix[idx,0,...] = F.interpolate(torch.from_numpy(nib.load(os.path.join(data_path,value['fixed'])).get_fdata()).float().unsqueeze(0).unsqueeze(0),scale_factor=.5,mode='trilinear').squeeze()\n",
    "    img_mov[idx,0,...] = F.interpolate(torch.from_numpy(nib.load(os.path.join(data_path,value['moving'])).get_fdata()).float().unsqueeze(0).unsqueeze(0),scale_factor=.5,mode='trilinear').squeeze()\n",
    "    mask_fix[idx,0,...] = F.interpolate(torch.from_numpy(nib.load(os.path.join(data_path,value['fixed'].replace('image','mask'))).get_fdata()).float().unsqueeze(0).unsqueeze(0),scale_factor=.5,mode='nearest').squeeze()\n",
    "    mask_mov[idx,0,...] = F.interpolate(torch.from_numpy(nib.load(os.path.join(data_path,value['moving'].replace('image','mask'))).get_fdata()).float().unsqueeze(0).unsqueeze(0),scale_factor=.5,mode='nearest').squeeze()\n",
    "print('done')\n",
    "img_fix*=mask_fix\n",
    "img_mov*=mask_mov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 # Conv2d > Conv3d and 15 #BatchNorms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_layer(model, name):\n",
    "    layer = model\n",
    "    for attr in name.split(\".\"):\n",
    "        layer = getattr(layer, attr)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def set_layer(model, name, layer):\n",
    "    try:\n",
    "        attrs, name = name.rsplit(\".\", 1)\n",
    "        model = get_layer(model, attrs)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    setattr(model, name, layer)\n",
    "import torchvision\n",
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "###\n",
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "resnet.layer4 = nn.Identity()\n",
    "resnet.avgpool = nn.Identity()#nn.PixelShuffle(2)\n",
    "resnet.maxpool = nn.MaxPool3d(2)\n",
    "\n",
    "resnet.fc = nn.Sequential(nn.Unflatten(1,(8*32//2,28,24,28)),nn.Upsample(scale_factor=2,mode='trilinear'))\n",
    "#,nn.Upsample(scale_factor=2,mode='trilinear'),nn.Conv3d(32,3,3,padding=1))\n",
    "#print(resnet.conv1)\n",
    "resnet.conv1 = nn.Conv2d(2,64,5,stride=1,padding=2)\n",
    "resnet.layer2[0].conv1.stride = (1,1)\n",
    "resnet.layer2[0].downsample[0].stride=1\n",
    "\n",
    "count = 0; count2 = 0\n",
    "for name, module in resnet.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        before = get_layer(resnet, name)\n",
    "        after = nn.Conv3d(before.in_channels//2,before.out_channels//2,int(torch.tensor(before.kernel_size)[0]),stride=int(torch.tensor(before.stride).view(-1)[0]),padding=before.padding[0])\n",
    "        set_layer(resnet, name, after); count += 1\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        before = get_layer(resnet, name)\n",
    "        after = nn.BatchNorm3d(before.num_features//2)\n",
    "        set_layer(resnet, name, after); count2 += 1\n",
    "print(count,'# Conv2d > Conv3d','and',count2,'#BatchNorms')\n",
    "resnet.cuda()\n",
    "print()\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(in_channels,out_channels,3,padding=1,bias=False),\\\n",
    "                                   nn.InstanceNorm3d(out_channels),nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(out_channels,out_channels,1,bias=False),\\\n",
    "                                   nn.InstanceNorm3d(out_channels),nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleDict({'enc1':ConvBlock(256,32),'enc2':ConvBlock(32,48),'enc3':ConvBlock(48,48),\\\n",
    "                                      'enc4':ConvBlock(48,64)})\n",
    "        self.decoder = nn.ModuleDict({'dec1':ConvBlock(64+48,48),\\\n",
    "                                      'dec2':ConvBlock(48+48,48),'dec3':ConvBlock(48+32,32)})\n",
    "        self.conv1 = ConvBlock(32,64)\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(64,32,1,bias=False),nn.InstanceNorm3d(32),nn.ReLU(inplace=True),\\\n",
    "                                 nn.Conv3d(32,32,1,bias=False),nn.InstanceNorm3d(32),nn.ReLU(inplace=True),\\\n",
    "                                 nn.Conv3d(32,3,1))\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        upsample = nn.Upsample(scale_factor=2,mode='trilinear')\n",
    "        for i in range(4):\n",
    "            x = self.encoder['enc'+str(i+1)](x)\n",
    "            if(i<3):\n",
    "                y.append(x)\n",
    "                x = F.max_pool3d(x,2) \n",
    "        for i in range(3):\n",
    "            #if(i<3):\n",
    "            x = torch.cat((upsample(x),y.pop()),1)\n",
    "            x = self.decoder['dec'+str(i+1)](x)\n",
    "        x = self.conv1(x)\n",
    "        return upsample(self.conv2(x))\n",
    "\n",
    "unet = UNet()\n",
    "unet.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.load_state_dict(torch.load('NLST_Example_resnet_trained_github.pth').state_dict())\n",
    "unet.load_state_dict(torch.load('NLST_Example_unet_trained_github.pth').state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.21005630493164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_inf = 0\n",
    "\n",
    "idx_test = range(101,111)\n",
    "\n",
    "out_path='outputs/'\n",
    "\n",
    "resnet.eval()\n",
    "unet.eval()\n",
    "with torch.inference_mode():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for idx,val in enumerate(idx_test):\n",
    "            torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            input = torch.cat((resnet(img_fix[idx:idx+1].cuda().half()),resnet(img_mov[idx:idx+1].cuda().half())),1).cuda()\n",
    "            output = unet(input)\n",
    "            \n",
    "            disp_field= F.interpolate(output,scale_factor=2,mode='trilinear')\n",
    "            disp_field=((disp_field.permute(0,2,3,4,1))*(torch.tensor([D,W,H]).cuda()-1)).flip(-1).float().squeeze().cpu()\n",
    "            nib.save(nib.Nifti1Image(disp_field.numpy(), np.eye(4)), os.path.join(out_path, f'disp_{str(val).zfill(4)}_{str(val).zfill(4)}.nii.gz'))\n",
    "            \n",
    "            t_inf += time.time()-t0\n",
    "print(t_inf,'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring NLST\n",
      "Evaluate 10 cases for: ['LogJacDetStd', 'TRE_kp']\n",
      "Will use masks for evaluation.\n",
      "case_results [0]: {'LogJacDetStd': 0.05709194370830525, 'TRE_kp': 3.5281835027863107}\n",
      "case_results [1]: {'LogJacDetStd': 0.04133854798122079, 'TRE_kp': 4.762279556245802}\n",
      "case_results [2]: {'LogJacDetStd': 0.042281379128080124, 'TRE_kp': 5.8877467888313255}\n",
      "case_results [3]: {'LogJacDetStd': 0.03195278304994823, 'TRE_kp': 7.240518992697461}\n",
      "case_results [4]: {'LogJacDetStd': 0.04000418510951741, 'TRE_kp': 6.029647681055934}\n",
      "case_results [5]: {'LogJacDetStd': 0.04428664051736225, 'TRE_kp': 9.883984352557025}\n",
      "case_results [6]: {'LogJacDetStd': 0.03627716745890451, 'TRE_kp': 4.438268441937357}\n",
      "case_results [7]: {'LogJacDetStd': 0.07834462087820306, 'TRE_kp': 4.054353200010246}\n",
      "case_results [8]: {'LogJacDetStd': 0.04351126247084735, 'TRE_kp': 7.671051105658131}\n",
      "case_results [9]: {'LogJacDetStd': 0.03881089500435125, 'TRE_kp': 4.035733856128705}\n",
      "{\n",
      "    \"LogJacDetStd\": {\n",
      "        \"30\": 0.03964619807796756,\n",
      "        \"std\": 0.013290186474093982,\n",
      "        \"mean\": 0.04538994253067403\n",
      "    },\n",
      "    \"TRE_kp\": {\n",
      "        \"30\": 4.323093869359223,\n",
      "        \"std\": 2.0150989310280565,\n",
      "        \"mean\": 5.75317674779083\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacement_fields= 'outputs/'\n",
    "data='../../Learn2Reg_Dataset_v11/' #Secret Validation Data for now\n",
    "output_dir=displacement_fields\n",
    "output_suffix='_NLSTexamp.json'\n",
    "for task in ['NLST']:\n",
    "    print('Staring', task)\n",
    "    _i=os.path.join(displacement_fields)\n",
    "    _d=os.path.join(data,task)\n",
    "    _o=os.path.join(output_dir,task+output_suffix)\n",
    "    _c=os.path.join('../../L2R/evaluation/evaluation_configs/NLST_VAL_evaluation_config.json')\n",
    "    !python ../../L2R/evaluation/evaluation.py -i {_i} -d {_d} -o{_o} -c{_c} -v\n",
    "    print(2*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ea9f0d30abf61677a25ad12401e4e23082d5add844bfb861bed0be870feaf59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
