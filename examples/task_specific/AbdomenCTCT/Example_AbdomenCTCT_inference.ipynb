{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "out_path='outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 20 ; Validation 10\n",
      "validaion data loaded in 3.43 s\n"
     ]
    }
   ],
   "source": [
    "##preload data\n",
    "\n",
    "data_path='../../../Learn2Reg_Dataset_release_v1.0/AbdomenCTCT/'\n",
    "with open(os.path.join(data_path,'AbdomenCTCT_dataset.json')) as f:\n",
    "    dataset_info=json.load(f)\n",
    "\n",
    "val_list=sorted(list(set([x['fixed'] for x in dataset_info['registration_val']] \n",
    "              + [x['moving'] for x in dataset_info['registration_val']])))\n",
    "validation_ = dataset_info['registration_val']\n",
    "training_ = [x for x in dataset_info['training'] if x['image'] not in val_list]\n",
    "H,W,D = dataset_info['tensorImageShape']['0']\n",
    "num_val=len(val_list); num_train=len(training_)\n",
    "print('Training:',len(training_),'; Validation',len(val_list))\n",
    "\n",
    "\n",
    "##validation\n",
    "seg_val = torch.zeros(num_val,H,W,D).long().pin_memory()\n",
    "img_val = torch.zeros(num_val,1,H//2,W//2,D//2).pin_memory()\n",
    "t0 = time.time()\n",
    "for ii,i in enumerate(val_list):\n",
    "    seg_val[ii] = torch.from_numpy(nib.load(os.path.join(data_path,i.replace('image','label'))).get_fdata()).long()\n",
    "    img_val[ii] = F.avg_pool3d(torch.from_numpy(nib.load(os.path.join(data_path,i)).get_fdata()).float().cuda().unsqueeze(0).unsqueeze(0)/500,2).cpu()\n",
    "t1 = time.time()\n",
    "print('validaion data loaded in %.2f s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### functions \n",
    "def jacobian_determinant_3d(dense_flow):\n",
    "    B,_,H,W,D = dense_flow.size()\n",
    "    \n",
    "    dense_pix = dense_flow*(torch.Tensor([H-1,W-1,D-1])/2).view(1,3,1,1,1).to(dense_flow.device)\n",
    "    gradz = nn.Conv3d(3,3,(3,1,1),padding=(1,0,0),bias=False,groups=3)\n",
    "    gradz.weight.data[:,0,:,0,0] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    gradz.to(dense_flow.device)\n",
    "    grady = nn.Conv3d(3,3,(1,3,1),padding=(0,1,0),bias=False,groups=3)\n",
    "    grady.weight.data[:,0,0,:,0] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    grady.to(dense_flow.device)\n",
    "    gradx = nn.Conv3d(3,3,(1,1,3),padding=(0,0,1),bias=False,groups=3)\n",
    "    gradx.weight.data[:,0,0,0,:] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(3,1)\n",
    "    gradx.to(dense_flow.device)\n",
    "    #with torch.no_grad():\n",
    "    jacobian = torch.cat((gradz(dense_pix),grady(dense_pix),gradx(dense_pix)),0)+torch.eye(3,3).view(3,3,1,1,1).to(dense_flow.device)\n",
    "    jacobian = jacobian[:,:,2:-2,2:-2,2:-2]\n",
    "    jac_det = jacobian[0,0,:,:,:]*(jacobian[1,1,:,:,:]*jacobian[2,2,:,:,:]-jacobian[1,2,:,:,:]*jacobian[2,1,:,:,:])-\\\n",
    "    jacobian[1,0,:,:,:]*(jacobian[0,1,:,:,:]*jacobian[2,2,:,:,:]-jacobian[0,2,:,:,:]*jacobian[2,1,:,:,:])+\\\n",
    "    jacobian[2,0,:,:,:]*(jacobian[0,1,:,:,:]*jacobian[1,2,:,:,:]-jacobian[0,2,:,:,:]*jacobian[1,1,:,:,:])\n",
    "\n",
    "    return jac_det\n",
    "\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = torch.mean(iflat * tflat)\n",
    "        dice[label_num-1] = (2. * intersection) / (1e-8 + torch.mean(iflat) + torch.mean(tflat))\n",
    "    return dice\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(in_channels,out_channels,3,padding=1,bias=False),\\\n",
    "                                   nn.BatchNorm3d(out_channels),nn.PReLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(out_channels,out_channels,1,bias=False),\\\n",
    "                                   nn.BatchNorm3d(out_channels),nn.PReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)\n",
    "    \n",
    "base_ch = 16\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleDict({'enc1':ConvBlock(64,base_ch*2),'enc2':ConvBlock(base_ch*2,base_ch*3),\\\n",
    "                                      'enc3':ConvBlock(base_ch*3,base_ch*3),'enc4':ConvBlock(base_ch*3,base_ch*4)})\n",
    "        self.decoder = nn.ModuleDict({'dec1':ConvBlock(base_ch*7,base_ch*3),\\\n",
    "                                      'dec2':ConvBlock(base_ch*6,base_ch*3),'dec3':ConvBlock(base_ch*5,base_ch*2)})\n",
    "        self.conv1 = ConvBlock(base_ch*2,base_ch*4)\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(base_ch*4,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,3,1))\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        upsample = nn.Upsample(scale_factor=2,mode='trilinear')\n",
    "        for i in range(4):\n",
    "            x = self.encoder['enc'+str(i+1)](x)\n",
    "            if(i<3):\n",
    "                y.append(x)\n",
    "                x = F.max_pool3d(x,2) \n",
    "        for i in range(3):\n",
    "            x = torch.cat((upsample(x),y.pop()),1)\n",
    "            x = self.decoder['dec'+str(i+1)](x)\n",
    "        x = self.conv1(x)\n",
    "        return F.avg_pool3d(F.avg_pool3d(upsample(self.conv2(x)),5,stride=1,padding=2),5,stride=1,padding=2)\n",
    "    \n",
    "class UNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleDict({'enc1':ConvBlock(1,base_ch*2),'enc2':ConvBlock(base_ch*2,base_ch*3),\\\n",
    "                                      'enc3':ConvBlock(base_ch*3,base_ch*3),'enc4':ConvBlock(base_ch*3,base_ch*4),\\\n",
    "                                      'enc5':ConvBlock(base_ch*4,base_ch*4)})\n",
    "        self.decoder = nn.ModuleDict({'dec1':ConvBlock(base_ch*8,base_ch*3),'dec2':ConvBlock(base_ch*6,base_ch*3),\\\n",
    "                                      'dec3':ConvBlock(base_ch*6,base_ch*3),'dec4':ConvBlock(base_ch*3,base_ch*2)})\n",
    "        self.conv1 = ConvBlock(base_ch*2,base_ch*4)\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(base_ch*4,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,base_ch*2,1,bias=False),nn.BatchNorm3d(base_ch*2),nn.PReLU(),\\\n",
    "                                 nn.Conv3d(base_ch*2,32,1))\n",
    "        self.final = nn.Identity()\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        upsample = nn.Upsample(scale_factor=2,mode='trilinear')\n",
    "        for i in range(5):\n",
    "            x = self.encoder['enc'+str(i+1)](x)\n",
    "            if(i<4):\n",
    "                y.append(x)\n",
    "                x = F.max_pool3d(x,2) \n",
    "        for i in range(4):\n",
    "            if(i<3):\n",
    "                x = torch.cat((upsample(x),y.pop()),1)\n",
    "            x = self.decoder['dec'+str(i+1)](x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.final(x)\n",
    "\n",
    "resnet = UNet2()\n",
    "\n",
    "resnet.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = torch.load('AbdomenCTCT_example_complete.pth')\n",
    "unet=UNet()\n",
    "unet.load_state_dict(models['unet'])\n",
    "resnet.load_state_dict(models['resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/functional.py:4255: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/share/data_supergrover1/grossbroehmer/miniconda3/envs/nnunet/lib/python3.10/site-packages/torch/nn/functional.py:4193: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved disp_0001_0004.nii.gz\n",
      "Saved disp_0001_0007.nii.gz\n",
      "Saved disp_0001_0010.nii.gz\n",
      "Saved disp_0001_0013.nii.gz\n",
      "Saved disp_0001_0016.nii.gz\n",
      "Saved disp_0001_0019.nii.gz\n",
      "Saved disp_0001_0022.nii.gz\n",
      "Saved disp_0001_0025.nii.gz\n",
      "Saved disp_0001_0028.nii.gz\n",
      "Saved disp_0004_0007.nii.gz\n",
      "Saved disp_0004_0010.nii.gz\n",
      "Saved disp_0004_0013.nii.gz\n",
      "Saved disp_0004_0016.nii.gz\n",
      "Saved disp_0004_0019.nii.gz\n",
      "Saved disp_0004_0022.nii.gz\n",
      "Saved disp_0004_0025.nii.gz\n",
      "Saved disp_0004_0028.nii.gz\n",
      "Saved disp_0007_0010.nii.gz\n",
      "Saved disp_0007_0013.nii.gz\n",
      "Saved disp_0007_0016.nii.gz\n",
      "Saved disp_0007_0019.nii.gz\n",
      "Saved disp_0007_0022.nii.gz\n",
      "Saved disp_0007_0025.nii.gz\n",
      "Saved disp_0007_0028.nii.gz\n",
      "Saved disp_0010_0013.nii.gz\n",
      "Saved disp_0010_0016.nii.gz\n",
      "Saved disp_0010_0019.nii.gz\n",
      "Saved disp_0010_0022.nii.gz\n",
      "Saved disp_0010_0025.nii.gz\n",
      "Saved disp_0010_0028.nii.gz\n",
      "Saved disp_0013_0016.nii.gz\n",
      "Saved disp_0013_0019.nii.gz\n",
      "Saved disp_0013_0022.nii.gz\n",
      "Saved disp_0013_0025.nii.gz\n",
      "Saved disp_0013_0028.nii.gz\n",
      "Saved disp_0016_0019.nii.gz\n",
      "Saved disp_0016_0022.nii.gz\n",
      "Saved disp_0016_0025.nii.gz\n",
      "Saved disp_0016_0028.nii.gz\n",
      "Saved disp_0019_0022.nii.gz\n",
      "Saved disp_0019_0025.nii.gz\n",
      "Saved disp_0019_0028.nii.gz\n",
      "Saved disp_0022_0025.nii.gz\n",
      "Saved disp_0022_0028.nii.gz\n",
      "Saved disp_0025_0028.nii.gz\n",
      "0.0375 sec/im Dice before (%) 25.14 Dice after (%) 45.63 std(Jac) 0.6442 neg(Jac) 0.021813\n"
     ]
    }
   ],
   "source": [
    "unet.cuda()\n",
    "resnet.cuda()\n",
    "unet.eval()\n",
    "resnet.eval()\n",
    "dice45 = torch.zeros(4,45)\n",
    "t_all = 0\n",
    "count = 0\n",
    "\n",
    "val_list_nr=[int(x[-16:-12]) for x in val_list]\n",
    "\n",
    "for i,val1 in enumerate(val_list_nr):\n",
    "    for j, val2 in enumerate(val_list_nr):\n",
    "        if(i>=j):\n",
    "            continue\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                feat = resnet(torch.cat((img_val[i:i+1].cuda(),img_val[j:j+1].cuda()),0))\n",
    "                input = torch.cat((feat[:1],feat[1:2]),1).cuda()\n",
    "\n",
    "                output = F.interpolate(unet(input),scale_factor=2,mode='trilinear')\n",
    "\n",
    "\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.time()   \n",
    "        t_all += (t1-t0)\n",
    "        with torch.no_grad():\n",
    "            seg_warped = F.grid_sample(seg_val[j:j+1].unsqueeze(1).float().contiguous().cuda(),output.permute(0,2,3,4,1)+F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H,W,D)),mode='nearest')\n",
    "            jac_det = jacobian_determinant_3d(output[:1])\n",
    "        d0 = dice_coeff(seg_val[i].cuda().contiguous(),seg_val[j].contiguous().cuda().long(),14).cpu()\n",
    "\n",
    "        nib_disp_field=((output.permute(0,2,3,4,1) /2)*(torch.tensor([D,W,H]).cuda()-1)).flip(-1).float().squeeze().cpu()\n",
    "        nib.save(nib.Nifti1Image(nib_disp_field.numpy(), np.eye(4)), os.path.join(out_path, f'disp_{str(val1).zfill(4)}_{str(val2).zfill(4)}.nii.gz'))\n",
    "        print(f'Saved disp_{str(val1).zfill(4)}_{str(val2).zfill(4)}.nii.gz')\n",
    "\n",
    "        d1 = dice_coeff(seg_val[i].cuda().contiguous(),seg_warped.contiguous().squeeze().long(),14).cpu()\n",
    "        #print(d1.mean(),d1)\n",
    "        dice45[0,count] = d0.mean()\n",
    "        dice45[1,count] = d1.mean()\n",
    "        dice45[2,count] = jac_det.std()\n",
    "        dice45[3,count] = (jac_det<0).float().mean()\n",
    "\n",
    "\n",
    "\n",
    "        count += 1\n",
    "    #print(d0.mean(),'after',d1.mean(),jac_det.std(),(jac_det<0).float().mean())\n",
    "\n",
    "print('%0.4f'%((t_all)/45),'sec/im','Dice before (%)','%0.2f'%(dice45.mean(1)[0].item()*100),\\\n",
    "      'Dice after (%)','%0.2f'%(dice45.mean(1)[1].item()*100),'std(Jac)','%0.4f'%(dice45.mean(1)[2].item()),\\\n",
    "     'neg(Jac)','%0.6f'%(dice45.mean(1)[3].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring AbdomenCTCT\n",
      "Evaluate 45 cases for: ['LogJacDetStd', 'DSC', 'HD95']\n",
      "case_results [0]: {'LogJacDetStd': 0.19564424713621664, 'DSC': 0.42361463170105124, 'HD95': 16.336788892209622}\n",
      "case_results [1]: {'LogJacDetStd': 0.40910771799212176, 'DSC': 0.41988416299836623, 'HD95': 13.8310298266488}\n",
      "case_results [2]: {'LogJacDetStd': 0.43348170926996576, 'DSC': 0.49952440400488946, 'HD95': 10.104615792306994}\n",
      "case_results [3]: {'LogJacDetStd': 0.1389824331355023, 'DSC': 0.5017108769899589, 'HD95': 10.710867758990679}\n",
      "case_results [4]: {'LogJacDetStd': 0.19372547490566755, 'DSC': 0.5161475037448059, 'HD95': 12.99845110980096}\n",
      "case_results [5]: {'LogJacDetStd': 0.31455199202966005, 'DSC': 0.46862124618244805, 'HD95': 13.294307036197644}\n",
      "case_results [6]: {'LogJacDetStd': 0.14431763526804345, 'DSC': 0.5135910774243343, 'HD95': 8.945338469473548}\n",
      "case_results [7]: {'LogJacDetStd': 0.1280621911388051, 'DSC': 0.551504405650682, 'HD95': 8.282858758622256}\n",
      "case_results [8]: {'LogJacDetStd': 0.21211482038035215, 'DSC': 0.5132457843485073, 'HD95': 7.739234504259747}\n",
      "case_results [9]: {'LogJacDetStd': 0.24032155922897333, 'DSC': 0.3860946532822925, 'HD95': 15.239261341436372}\n",
      "case_results [10]: {'LogJacDetStd': 0.9916229547134351, 'DSC': 0.3944392101763201, 'HD95': 14.519160710069247}\n",
      "case_results [11]: {'LogJacDetStd': 0.6939209423613644, 'DSC': 0.3965504812102589, 'HD95': 14.608363461597}\n",
      "case_results [12]: {'LogJacDetStd': 0.8754419319605232, 'DSC': 0.4040809499374615, 'HD95': 15.22173558721997}\n",
      "case_results [13]: {'LogJacDetStd': 0.9264063682059555, 'DSC': 0.38514625715549894, 'HD95': 14.301307157095966}\n",
      "case_results [14]: {'LogJacDetStd': 0.2858476542245167, 'DSC': 0.4454400327292736, 'HD95': 11.270237418502198}\n",
      "case_results [15]: {'LogJacDetStd': 0.5790570626816834, 'DSC': 0.47509862705476574, 'HD95': 11.426585444682665}\n",
      "case_results [16]: {'LogJacDetStd': 0.4818777719353339, 'DSC': 0.40544934809361605, 'HD95': 13.510479053605065}\n",
      "case_results [17]: {'LogJacDetStd': 0.5681806048455533, 'DSC': 0.43680368449676393, 'HD95': 12.703886607464616}\n",
      "case_results [18]: {'LogJacDetStd': 0.2394045070638744, 'DSC': 0.4010045125741797, 'HD95': 15.165355011710082}\n",
      "case_results [19]: {'LogJacDetStd': 0.4999524965558119, 'DSC': 0.44120821525983894, 'HD95': 10.438261863008446}\n",
      "case_results [20]: {'LogJacDetStd': 0.34814667395193594, 'DSC': 0.416127426998685, 'HD95': 16.087622842151863}\n",
      "case_results [21]: {'LogJacDetStd': 0.2787190559702908, 'DSC': 0.4338841080107529, 'HD95': 14.17677274905054}\n",
      "case_results [22]: {'LogJacDetStd': 0.4345097269053956, 'DSC': 0.4736982170504353, 'HD95': 13.348645866212783}\n",
      "case_results [23]: {'LogJacDetStd': 0.4276974723964164, 'DSC': 0.4192525159277485, 'HD95': 13.56706320914886}\n",
      "case_results [24]: {'LogJacDetStd': 0.33376761093038854, 'DSC': 0.4748475576633678, 'HD95': 20.69405571414618}\n",
      "case_results [25]: {'LogJacDetStd': 0.24877515136899286, 'DSC': 0.5419226807646544, 'HD95': 8.885473402032831}\n",
      "case_results [26]: {'LogJacDetStd': 0.5586491282142246, 'DSC': 0.45178409940729364, 'HD95': 14.913955392558679}\n",
      "case_results [27]: {'LogJacDetStd': 0.21621601257727052, 'DSC': 0.5119092463653637, 'HD95': 13.821051504599101}\n",
      "case_results [28]: {'LogJacDetStd': 0.25059538025654954, 'DSC': 0.5059191612153565, 'HD95': 15.270178765540258}\n",
      "case_results [29]: {'LogJacDetStd': 0.293725817810779, 'DSC': 0.5336805449102908, 'HD95': 9.671875509822705}\n",
      "case_results [30]: {'LogJacDetStd': 0.7561965409490609, 'DSC': 0.5041405641325208, 'HD95': 8.573163625649807}\n",
      "case_results [31]: {'LogJacDetStd': 0.5817258812230671, 'DSC': 0.4880421099677625, 'HD95': 11.116459275877355}\n",
      "case_results [32]: {'LogJacDetStd': 0.4318833977259658, 'DSC': 0.4863004713701348, 'HD95': 12.070872529629208}\n",
      "case_results [33]: {'LogJacDetStd': 0.3957810188732069, 'DSC': 0.4525969858494003, 'HD95': 13.2510748508808}\n",
      "case_results [34]: {'LogJacDetStd': 0.4332229821333659, 'DSC': 0.5378533667397506, 'HD95': 9.272292610047725}\n",
      "case_results [35]: {'LogJacDetStd': 0.2048675045165575, 'DSC': 0.49298067711509935, 'HD95': 13.223203589959347}\n",
      "case_results [36]: {'LogJacDetStd': 0.2936320417691495, 'DSC': 0.49431297710623057, 'HD95': 13.592751611057151}\n",
      "case_results [37]: {'LogJacDetStd': 0.24607049417847965, 'DSC': 0.4788699104458798, 'HD95': 15.483386996993652}\n",
      "case_results [38]: {'LogJacDetStd': 0.30506868202485754, 'DSC': 0.5031917536750785, 'HD95': 12.977066839842472}\n",
      "case_results [39]: {'LogJacDetStd': 0.32943496816073903, 'DSC': 0.461302729452238, 'HD95': 12.5915972874265}\n",
      "case_results [40]: {'LogJacDetStd': 0.4258080926241207, 'DSC': 0.45645486876864044, 'HD95': 16.209171981065893}\n",
      "case_results [41]: {'LogJacDetStd': 0.6134772341447176, 'DSC': 0.4753317639195508, 'HD95': 12.380633307168027}\n",
      "case_results [42]: {'LogJacDetStd': 0.14161034121441113, 'DSC': 0.5494175674301458, 'HD95': 6.491898904102382}\n",
      "case_results [43]: {'LogJacDetStd': 0.2656513852271496, 'DSC': 0.5212053816006971, 'HD95': 6.914969684621353}\n",
      "case_results [44]: {'LogJacDetStd': 0.2243455832222607, 'DSC': 0.538500313138894, 'HD95': 7.290549505500343}\n",
      "{\n",
      "    \"LogJacDetStd\": {\n",
      "        \"30\": 0.2491391971465042,\n",
      "        \"std\": 0.21121810013678063,\n",
      "        \"mean\": 0.39092445007561577\n",
      "    },\n",
      "    \"DSC\": {\n",
      "        \"30\": 0.4420545787537259,\n",
      "        \"std\": 0.048273986387390215,\n",
      "        \"mean\": 0.47072637920091753\n",
      "    },\n",
      "    \"HD95\": {\n",
      "        \"30\": 11.147214904402324,\n",
      "        \"std\": 2.976055969034395,\n",
      "        \"mean\": 12.50053140799973\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Check Evaluation\n",
    "\n",
    "config_files_dir='../../evaluation/evaluation_configs'\n",
    "output_suffix='_example.json'\n",
    "for task in ['AbdomenCTCT']:\n",
    "    print('Staring', task)\n",
    "    _i=os.path.join(out_path)\n",
    "    _d=os.path.join(data_path)\n",
    "    _o=os.path.join('.',task+output_suffix)\n",
    "    _c=os.path.join(config_files_dir,task+\"_VAL_evaluation_config.json\")\n",
    "    !python /share/data_zoe3/grossbroehmer/Learn2Reg2022/L2R/evaluation/evaluation.py -i {_i} -d {_d} -o{_o} -c{_c} -v\n",
    "    print(2*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ea9f0d30abf61677a25ad12401e4e23082d5add844bfb861bed0be870feaf59"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
